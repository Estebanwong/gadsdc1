The Netflix Prize
========================================================

The Netflix Prize was announced in 2006, awarding $1M to the first team to improve on Netflix's internal system for predicting user movie ratings by at least 10%.  An 8.4% reduction was achieved in year one, but the final prize was not awarded until 2009 with a nail-biting finish between two mega-teams using large ensembles of models to achieve the final 10% reduction.

There are many fascinating aspects of the contest from both the business and technical point of view.  In this presentation we will cover a few of these ideas, including the problem formulation, nearest neighbor methods for collaborative filtering, latent factor analysis for scoring movies and learning user preferences, the improvements that ensembles of models bring, and final business implications.

The competition and winning algorithm have been well documented, and I highly encourage interested folks to go to the source.  [This paper] (http://www2.research.att.com/~volinsky/papers/chance.pdf) from the winning team is more general interest than academic, and covers both the algorithms and a bit of the drama.  [This blog post] (http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html) from Netflix in 2012 reveals which of the winning solutions was (and was not) implemented - it's an important lesson to those of us who hope to see our data products in action!  My humble presentation is [here] (http://www.slideshare.net/HollyWH/the-netflix-prize).  


